{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.output_nodes))\n",
    "        self.lr = learning_rate\n",
    "        #sigmoid activation function\n",
    "        def sigmoid(self,x):\n",
    "            return (1/(1 + np.exp(-x)))\n",
    "        \n",
    "        #derivate of sigmoid activation function\n",
    "        def sigmoid_prime(self,x):\n",
    "            return x * (1 - x) #Equivalent to output * (1 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward_pass_train(self, X):\n",
    "        ''' Implement forward pass here \n",
    "            Arguments\n",
    "            ---------\n",
    "            X: features batch\n",
    "        '''\n",
    "        #### Implement the forward pass here ####\n",
    "        ### Forward pass ###\n",
    "        hidden_inputs = np.dot(X, self.weights_input_to_hidden) # signals into hidden layer\n",
    "        hidden_outputs = self.sigmoid(hidden_inputs) # signals from hidden layer\n",
    "\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "        final_outputs = self.sigmoid(final_inputs) # signals from final output layer\n",
    "        \n",
    "        return final_outputs, hidden_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o):\n",
    "        ''' Implement backpropagation\n",
    "            Arguments\n",
    "            ---------\n",
    "            final_outputs: output from forward pass\n",
    "            y: target (i.e. label) batch\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "\n",
    "        '''\n",
    "        #### Implement the backward pass here ####\n",
    "        ### Backward pass ###\n",
    "        error = y - final_outputs # Output layer error is the difference between desired target and actual output.\n",
    "        output_error_term = error * self.sigmoid_prime(final_outputs)\n",
    "        \n",
    "        hidden_error = np.dot(self.weights_hidden_to_output,error)\n",
    "        hidden_error_term = hidden_error * self.sigmoid_prime(hidden_outputs)\n",
    "        \n",
    "        # Weight step (input to hidden)\n",
    "        delta_weights_i_h += hidden_error_term * X[:, None]\n",
    "        # Weight step (hidden to output)\n",
    "        delta_weights_h_o += output_error_term * hidden_outputs[:,None]\n",
    "        return delta_weights_i_h, delta_weights_h_o    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n",
    "        ''' Update weights on gradient descent step\n",
    "            Arguments\n",
    "            ---------\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "            n_records: number of records\n",
    "        '''\n",
    "        self.weights_hidden_to_output += self.lr * delta_weights_h_o/n_records #update hidden-to-output weights with gradient descent step\n",
    "        self.weights_input_to_hidden += self.lr * delta_weights_i_h/n_records # update input-to-hidden weights with gradient descent step\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def run(self, features):\n",
    "        ''' Run a forward pass through the network with input features \n",
    "            Arguments\n",
    "            ---------\n",
    "            features: 1D array of feature values\n",
    "        '''\n",
    "        #### Implement the forward pass here ####\n",
    "        hidden_inputs = np.dot(features, self.weights_input_to_hidden) # signals into hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "        \n",
    "        final_outpu = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "        \n",
    "        # signals from final output layer \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 4500\n",
    "learning_rate = 0.40\n",
    "hidden_nodes = 12\n",
    "output_nodes = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
