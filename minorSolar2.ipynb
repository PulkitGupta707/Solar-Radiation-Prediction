{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('SolarDataProcessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn import preprocessing\\nfrom sklearn.model_selection import train_test_split\\nx = df[df.columns[:10]]\\ny = df['ALLSKY_SFC_SW_DWN']\\nx_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state =  90)\\n#Select numerical columns which needs to be normalized\\ntrain_norm = x_train[x_train.columns[0:10]]\\ntest_norm = x_test[x_test.columns[0:10]]\\n# Normalize Training Data \\nstd_scale = preprocessing.StandardScaler().fit(train_norm)\\nx_train_norm = std_scale.transform(train_norm)\\n#Converting numpy array to dataframe\\ntraining_norm_col = pd.DataFrame(x_train_norm, index=train_norm.index, columns=train_norm.columns) \\nx_train.update(training_norm_col)\\n#x_train.head()\\n# Normalize Testing Data by using mean and SD of training set\\nx_test_norm = std_scale.transform(test_norm)\\ntesting_norm_col = pd.DataFrame(x_test_norm, index=test_norm.index, columns=test_norm.columns) \\nx_test.update(testing_norm_col)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = df[df.columns[:10]]\n",
    "y = df['ALLSKY_SFC_SW_DWN']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state =  90)\n",
    "#Select numerical columns which needs to be normalized\n",
    "train_norm = x_train[x_train.columns[0:10]]\n",
    "test_norm = x_test[x_test.columns[0:10]]\n",
    "# Normalize Training Data \n",
    "std_scale = preprocessing.StandardScaler().fit(train_norm)\n",
    "x_train_norm = std_scale.transform(train_norm)\n",
    "#Converting numpy array to dataframe\n",
    "training_norm_col = pd.DataFrame(x_train_norm, index=train_norm.index, columns=train_norm.columns) \n",
    "x_train.update(training_norm_col)\n",
    "#x_train.head()\n",
    "# Normalize Testing Data by using mean and SD of training set\n",
    "x_test_norm = std_scale.transform(test_norm)\n",
    "testing_norm_col = pd.DataFrame(x_test_norm, index=test_norm.index, columns=test_norm.columns) \n",
    "x_test.update(testing_norm_col)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rohan\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df[df.columns[:10]]\n",
    "y = df['ALLSKY_SFC_SW_DWN']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state =  90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT ML CLASSIFIERS\n",
    "from sklearn.linear_model import LinearRegression # Linear regression\n",
    "from sklearn.ensemble import RandomForestRegressor # random forest regression\n",
    "from sklearn.neural_network import MLPRegressor # neural network regression\n",
    "from sklearn.svm import SVR # support vector regression\n",
    "\n",
    "from sklearn import preprocessing # ML tools\n",
    "from sklearn.model_selection import train_test_split # split data\n",
    "\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "\n",
    "def plot_test(clf,X_test,y_test):\n",
    "    y_predicted = clf.predict(X_test)\n",
    "\n",
    "    p = figure(tools='pan,box_zoom,reset',x_range=[0, 100], title='Predicted vs Actual',y_axis_label='radiation')\n",
    "    p.grid.minor_grid_line_color = '#eeeeee'\n",
    "\n",
    "    p.line(range(len(y_test)),y_test,legend='actual',line_color='blue',line_width=2)\n",
    "    p.line(range(len(y_test)),y_predicted,legend='prediction',line_color='red',line_width=2)\n",
    "    output_notebook()\n",
    "    show(p)\n",
    "    return\n",
    "\n",
    "'''def plot_real(clf,x,y_actual,index):\n",
    "     Plot predictions for actual measurements.\n",
    "    inputs:\n",
    "        clf         as classifier   the trained algorithm\n",
    "        x           as array        timeseries of measurement inputs\n",
    "        y_actual    as array        corresponding timeseries of actual results\n",
    "    \n",
    "    y_predicted = clf.predict(x)\n",
    "\n",
    "    p = figure(toolbar_location='right', title='Predicted vs Actual',y_axis_label='radiation',x_axis_type=\"datetime\")\n",
    "    p.grid.minor_grid_line_color = '#eeeeee'\n",
    "\n",
    "    p.line(index,y_actual,legend='actual',line_color='blue')\n",
    "    p.line(index,y_predicted,legend='prediction',line_color='red')\n",
    "    output_notebook()\n",
    "    show(p)\n",
    "    return'''\n",
    "\n",
    "def train_model(x_train, x_test, y_train, y_test,clf,debug=False):\n",
    "    ''' Train algorithm.\n",
    "    inputs:\n",
    "        x       as array        features\n",
    "        y       as array        label(s)\n",
    "        clf     as scikit-learn classifier (untrained)\n",
    "    returns:\n",
    "        clf     as trained classifier\n",
    "        accuracy  as float\n",
    "    '''\n",
    "    model = clf.fit(x_train,y_train)\n",
    "    accuracy = clf.score(x_test,y_test)\n",
    "    return clf, model, accuracy,x_test, y_test\n",
    "\n",
    "def go(x_train, x_test, y_train, y_test,algorithm,debug=True):\n",
    "    ''' Easy model train and test. '''\n",
    "    clf, model, accuracy, x_test, y_test=train_model(x_train, x_test, y_train, y_test,algorithm,debug=True)\n",
    "    print('Accuracy: %s percent'%str(accuracy*100))\n",
    "\n",
    "    if debug:\n",
    "        plot_test(clf,x_test,y_test)\n",
    "        #plot_real(clf,x,y,df.index.values)\n",
    "    return\n",
    "\n",
    "def optimize_randomforest(x,y,try_n=10,try_f='auto',try_s=1):\n",
    "    ''' Find best combo of tunable params for random forest regressor. '''\n",
    "    best_score = float('-inf') # initialize score\n",
    "    for n in try_n:\n",
    "        for f in try_f:\n",
    "            for s in try_s:\n",
    "                clf = RandomForestRegressor(oob_score=True,n_estimators=n,max_features=f,min_samples_leaf=s,n_jobs=-1)\n",
    "                clf.fit(x,y)\n",
    "                if clf.oob_score_ > best_score:\n",
    "                    best_score, best_clf, best_n, best_f, best_s = clf.oob_score_, clf, n, f, s\n",
    "    return clf, best_n, best_f, best_s\n",
    "\n",
    "n=[100,200,300,500]\n",
    "f=[2,4,6]\n",
    "s=[1,2,4,8,16]\n",
    "clf, n, f, s = optimize_randomforest(x_train,y_train,try_n=n,try_f=f,try_s=s)\n",
    "print('n_estimators: '+str(n))\n",
    "print('max_features: '+str(f))\n",
    "print('min_samples_leaf: '+str(s))\n",
    "#go(x_train, x_test, y_train, y_test,RandomForestRegressor(n_estimators=n,max_features=f,min_samples_leaf=s,n_jobs=-1))\n",
    "#go(x_train, x_test, y_train, y_test,LinearRegression())\n",
    "go(x_train, x_test, y_train, y_test,SVR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "scores = []\n",
    "best_svr = SVR(kernel='rbf')\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(\"Train Index: \", train_index, \"\\n\")\n",
    "    print(\"Test Index: \", test_index)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    best_svr.fit(X_train, y_train)\n",
    "    scores.append(best_svr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9311400515228957\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['MO','DY'], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
