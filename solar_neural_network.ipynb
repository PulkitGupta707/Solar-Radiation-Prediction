{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECTOT</th>\n",
       "      <th>QV2M</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>PS</th>\n",
       "      <th>TS</th>\n",
       "      <th>T2M</th>\n",
       "      <th>T2MWET</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>ALLSKY_SFC_LW_DWN</th>\n",
       "      <th>KT</th>\n",
       "      <th>ALLSKY_SFC_SW_DWN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>45.36</td>\n",
       "      <td>98.82</td>\n",
       "      <td>13.57</td>\n",
       "      <td>14.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.72</td>\n",
       "      <td>7.72</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>45.54</td>\n",
       "      <td>99.19</td>\n",
       "      <td>13.71</td>\n",
       "      <td>14.83</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.85</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>41.00</td>\n",
       "      <td>99.06</td>\n",
       "      <td>13.46</td>\n",
       "      <td>15.08</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.57</td>\n",
       "      <td>7.72</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>42.18</td>\n",
       "      <td>99.15</td>\n",
       "      <td>13.91</td>\n",
       "      <td>15.21</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.12</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.43</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>64.49</td>\n",
       "      <td>98.91</td>\n",
       "      <td>13.46</td>\n",
       "      <td>14.43</td>\n",
       "      <td>7.74</td>\n",
       "      <td>7.74</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRECTOT      QV2M   RH2M     PS     TS    T2M  T2MWET  T2MDEW  \\\n",
       "0     0.02  0.004819  45.36  98.82  13.57  14.78    2.76    2.72   \n",
       "1     0.03  0.004835  45.54  99.19  13.71  14.83    2.89    2.85   \n",
       "2     0.01  0.004429  41.00  99.06  13.46  15.08    1.63    1.57   \n",
       "3     0.01  0.004591  42.18  99.15  13.91  15.21    2.16    2.12   \n",
       "4     6.43  0.006701  64.49  98.91  13.46  14.43    7.74    7.74   \n",
       "\n",
       "   ALLSKY_SFC_LW_DWN    KT  ALLSKY_SFC_SW_DWN  \n",
       "0               7.72  0.40               2.34  \n",
       "1               8.08  0.35               2.06  \n",
       "2               7.72  0.40               2.34  \n",
       "3               8.08  0.35               2.06  \n",
       "4               8.67  0.25               1.43  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SolarDelhi.csv', index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6816 entries, 0 to 6815\n",
      "Data columns (total 11 columns):\n",
      "PRECTOT              6816 non-null float64\n",
      "QV2M                 6816 non-null float64\n",
      "RH2M                 6816 non-null float64\n",
      "PS                   6816 non-null float64\n",
      "TS                   6816 non-null float64\n",
      "T2M                  6816 non-null float64\n",
      "T2MWET               6816 non-null float64\n",
      "T2MDEW               6816 non-null float64\n",
      "ALLSKY_SFC_LW_DWN    6816 non-null float64\n",
      "KT                   6816 non-null float64\n",
      "ALLSKY_SFC_SW_DWN    6816 non-null float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 639.0 KB\n"
     ]
    }
   ],
   "source": [
    "df['KT'] = df['KT'].astype(float)\n",
    "df[df == -999] = np.nan\n",
    "(df<0).any()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n",
    "                                       (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.output_nodes))\n",
    "        self.lr = learning_rate\n",
    "    \n",
    "    #sigmoid activation function\n",
    "    def sigmoid(self,x):\n",
    "        return (1/(1 + np.exp(-x)))\n",
    "        \n",
    "    #derivate of sigmoid activation function\n",
    "    def sigmoid_prime(self,x):\n",
    "        return x * (1 - x) #Equivalent to output * (1 - output)\n",
    "        \n",
    "    def train(self, features, targets):\n",
    "            ''' Train the network on batch of features and targets. \n",
    "            Arguments\n",
    "            ---------  \n",
    "            features: 2D array, each row is one data record, each column is a feature\n",
    "            targets: 1D array of target values \n",
    "            '''\n",
    "            n_records = features.shape[0]\n",
    "            delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "            delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "            for X, y in zip(features, targets):\n",
    "                final_outputs, hidden_outputs = self.forward_pass_train(X)  # Implement the forward pass function below\n",
    "                # Implement the backproagation function below\n",
    "                delta_weights_i_h, delta_weights_h_o = self.backpropagation(final_outputs, hidden_outputs, X, y, \n",
    "                                                                                delta_weights_i_h, delta_weights_h_o)\n",
    "                self.update_weights(delta_weights_i_h, delta_weights_h_o, n_records)\n",
    "        \n",
    "    def forward_pass_train(self, X):\n",
    "        ''' Implement forward pass here \n",
    "        Arguments\n",
    "        ---------\n",
    "        X: features batch\n",
    "        '''\n",
    "        #### Implement the forward pass here ####\n",
    "        ### Forward pass ###\n",
    "        hidden_inputs = np.dot(X, self.weights_input_to_hidden) # signals into hidden layer\n",
    "        hidden_outputs = self.sigmoid(hidden_inputs) # signals from hidden layer\n",
    "\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "        final_outputs = self.sigmoid(final_inputs) # signals from final output layer\n",
    "\n",
    "        return final_outputs, hidden_outputs\n",
    "        \n",
    "    def backpropagation(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o):\n",
    "        ''' Implement backpropagation\n",
    "            Arguments\n",
    "            ---------\n",
    "            final_outputs: output from forward pass\n",
    "            y: target (i.e. label) batch\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "        '''\n",
    "        #### Implement the backward pass here ####\n",
    "        ### Backward pass ###\n",
    "        error = y - final_outputs # Output layer error is the difference between desired target and actual output.\n",
    "        output_error_term = error * self.sigmoid_prime(final_outputs)\n",
    "\n",
    "        hidden_error = np.dot(self.weights_hidden_to_output,error)\n",
    "        hidden_error_term = hidden_error * self.sigmoid_prime(hidden_outputs)\n",
    "\n",
    "        # Weight step (input to hidden)\n",
    "        delta_weights_i_h += hidden_error_term * X[:, None]\n",
    "        # Weight step (hidden to output)\n",
    "        delta_weights_h_o += output_error_term * hidden_outputs[:,None]\n",
    "        return delta_weights_i_h, delta_weights_h_o    \n",
    "\n",
    "    def update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n",
    "        ''' Update weights on gradient descent step\n",
    "            Arguments\n",
    "            ---------\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "            n_records: number of records\n",
    "        '''\n",
    "        self.weights_hidden_to_output += self.lr * delta_weights_h_o/n_records #update hidden-to-output weights with gradient descent step\n",
    "        self.weights_input_to_hidden += self.lr * delta_weights_i_h/n_records # update input-to-hidden weights with gradient descent stepdef update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n",
    "        \n",
    "    def run(self, features):\n",
    "        ''' Run a forward pass through the network with input features \n",
    "            Arguments\n",
    "            ---------\n",
    "            features: 1D array of feature values\n",
    "        '''\n",
    "        #### Implement the forward pass here ####\n",
    "        hidden_inputs = np.dot(features, self.weights_input_to_hidden) # signals into hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs) # signals from hidden layer\n",
    "\n",
    "        final_outputs = np.dot(hidden_outputs, self.weights_hidden_to_output) # signals into final output layer\n",
    "\n",
    "        # signals from final output layer \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PRECTOT      QV2M   RH2M     PS     TS    T2M  T2MWET  T2MDEW  \\\n",
      "2516     0.86  0.015326  53.36  97.67  31.49  30.90   20.26   20.26   \n",
      "6410     0.00  0.009473  28.25  97.78  35.61  33.73   12.70   12.78   \n",
      "4993     4.61  0.012037  33.22  97.70  37.98  35.08   16.12   16.46   \n",
      "3383     0.00  0.005784  19.48  97.96  33.13  31.64    5.42    5.40   \n",
      "5189    24.13  0.021562  77.20  97.30  30.78  30.28   25.84   25.94   \n",
      "...       ...       ...    ...    ...    ...    ...     ...     ...   \n",
      "2727     0.00  0.003831  24.24  98.92  18.97  21.13   -0.11   -0.23   \n",
      "1347     0.00  0.005148  39.38  99.07  18.09  18.08    4.09    4.06   \n",
      "5746     0.00  0.005166  46.05  98.85  14.41  15.63    4.05    4.03   \n",
      "2717     0.00  0.003201  20.51  98.84  18.91  20.91   -2.40   -2.60   \n",
      "3931     0.00  0.016150  61.52  97.95  29.31  29.37   21.20   21.20   \n",
      "\n",
      "      ALLSKY_SFC_LW_DWN    KT  \n",
      "2516              10.12  0.60  \n",
      "6410              10.42  0.42  \n",
      "4993              10.66  0.58  \n",
      "3383               9.00  0.66  \n",
      "5189              11.58  0.40  \n",
      "...                 ...   ...  \n",
      "2727               7.32  0.60  \n",
      "1347               7.76  0.59  \n",
      "5746               6.89  0.59  \n",
      "2717               7.80  0.59  \n",
      "3931              10.03  0.60  \n",
      "\n",
      "[5452 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df[df.columns[:10]]\n",
    "y = df['ALLSKY_SFC_SW_DWN']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.8, random_state =  90)\n",
    "\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_i = x_train.shape[1]\n",
    "iterations = 40\n",
    "learning_rate = 0.40\n",
    "hidden_nodes = 6\n",
    "output_nodes = 1\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('float64') to dtype('<U32') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e212b60e9a97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Printing out the training progress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-94872649c281>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, features, targets)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mdelta_weights_h_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_hidden_to_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mfinal_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_pass_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Implement the forward pass function below\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[1;31m# Implement the backproagation function below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 delta_weights_i_h, delta_weights_h_o = self.backpropagation(final_outputs, hidden_outputs, X, y, \n",
      "\u001b[1;32m<ipython-input-4-94872649c281>\u001b[0m in \u001b[0;36mforward_pass_train\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m#### Implement the forward pass here ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m### Forward pass ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mhidden_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_input_to_hidden\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# signals into hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mhidden_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_inputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# signals from hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot cast array data from dtype('float64') to dtype('<U32') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n",
    "losses = {'train':[], 'validation':[]}\n",
    "for i in range(iterations):\n",
    "    # Go through a random batch of 150 records from the training data set\n",
    "    for j in range(x_train.shape[0] - batch_size):\n",
    "        x = x_train[j:batch_size]\n",
    "        y = y_train[j:batch_size]\n",
    "        j = j + batch_size\n",
    "        network.train(x,y)\n",
    "        \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.run(train_features).T, train_targets['cnt'].values)\n",
    "    val_loss = MSE(network.run(val_features).T, val_targets['cnt'].values)\n",
    "    sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * ii/float(iterations)) \\\n",
    "                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGDtJREFUeJzt3XuQVOW57/HvE0CIgtzEeJmwwWglDjjApIOkNAJeUGIZvJAISkRjQmmuO5RVEmOioqlC41aC8SQh2aEs5Ug8WkaON0oNkXhySh2IQdGwBxXLCRwFFCLiJaPv+WPa2fNiDzNM9zCM+X6qunpdnrX6eWeq5tdrre41kVJCkqQPfKyrG5Ak7V0MBklSxmCQJGUMBklSxmCQJGUMBklSxmCQJGUMBklSxmCQJGV6dnUDHXHAAQekYcOGdXUbktStrFy5cnNKaUhbdd0yGIYNG0ZdXV1XtyFJ3UpEvNSeOk8lSZIyBoMkKWMwSJIy3fIag6Q965///CcNDQ28/fbbXd2K2qFPnz5UVVXRq1evDm1vMEhqU0NDA/369WPYsGFERFe3o11IKbFlyxYaGhoYPnx4h/bhqSRJbXr77bcZPHiwodANRASDBw8u6+jOYJDULoZC91Hu78pgkCRlDAZJe70tW7YwevRoRo8ezUEHHcShhx7aPP/uu++2ax8XXHABa9eu3WXNzTffzOLFiyvRMsceeyxPPfVURfa1p3nxWdJeb/Dgwc1/ZK+88kr69u3LJZdcktWklEgp8bGPlX6/u2jRojZf51vf+lb5zX4EeMQgqdtat24dI0eO5KKLLqK2tpaNGzcya9YsCoUCI0aMYO7cuc21H7yDb2xsZMCAAcyZM4dRo0bx+c9/nldffRWAyy+/nPnz5zfXz5kzh7Fjx/LpT3+aP//5zwC8+eabnHXWWYwaNYrp06dTKBTaPDK47bbbOOqooxg5ciSXXXYZAI2NjXz1q19tXr5gwQIAbrzxRqqrqxk1ahQzZsyo+M+sPTxikLRbrvrfa3h2wz8qus/qQ/bnitNGdGjbZ599lkWLFvHLX/4SgHnz5jFo0CAaGxuZOHEiU6dOpbq6Ottm27ZtjB8/nnnz5jF79mx++9vfMmfOnA/tO6XEE088wdKlS5k7dy4PPvggN910EwcddBB33XUXf/3rX6mtrd1lfw0NDVx++eXU1dXRv39/TjzxRO69916GDBnC5s2befrppwHYunUrANdddx0vvfQS++yzT/OyPc0jBknd2qc+9Sk+97nPNc/ffvvt1NbWUltby3PPPcezzz77oW0+/vGPM3nyZAA++9nPsn79+pL7PvPMMz9U89hjjzFt2jQARo0axYgRuw60xx9/nOOPP54DDjiAXr16cc4557BixQoOP/xw1q5dy/e+9z2WLVtG//79ARgxYgQzZsxg8eLFHf6CWrk8YpC0Wzr6zr6z7Lfffs3T9fX1/OxnP+OJJ55gwIABzJgxo+Tn+ffZZ5/m6R49etDY2Fhy37179/5QTUppt/prrX7w4MGsXr2aBx54gAULFnDXXXexcOFCli1bxqOPPso999zDNddcwzPPPEOPHj126zXL5RGDpI+Mf/zjH/Tr14/999+fjRs3smzZsoq/xrHHHssdd9wBwNNPP13yiKSlcePGsXz5crZs2UJjYyNLlixh/PjxbNq0iZQSX/7yl7nqqqtYtWoV7733Hg0NDRx//PH89Kc/ZdOmTezYsaPiY2iLRwySPjJqa2uprq5m5MiRHHbYYRxzzDEVf43vfOc7nHfeedTU1FBbW8vIkSObTwOVUlVVxdy5c5kwYQIpJU477TROPfVUVq1axYUXXkhKiYjg2muvpbGxkXPOOYc33niD999/n0svvZR+/fpVfAxtid09LNobFAqF5D/qkfac5557jiOPPLKr29grNDY20tjYSJ8+faivr2fSpEnU19fTs+fe9T671O8sIlamlAptbbt3jUSS9nLbt2/nhBNOoLGxkZQSv/rVr/a6UCjXR2s0ktTJBgwYwMqVK7u6jU7lxWdJUsZgkCRlDAZJUsZgkCRlDAZJe70JEyZ86Mtq8+fP55vf/OYut+vbty8AGzZsYOrUqa3uu62Pv8+fPz/7otkXv/jFitzH6Morr+T6668vez+VVpFgiIhTImJtRKyLiA/diSoiekfE74rrH4+IYTutHxoR2yPikp23laTp06ezZMmSbNmSJUuYPn16u7Y/5JBDuPPOOzv8+jsHw/3338+AAQM6vL+9XdnBEBE9gJuByUA1MD0iqncquxB4PaV0OHAjcO1O628EHii3F0kfTVOnTuXee+/lnXfeAWD9+vVs2LCBY489tvl7BbW1tRx11FHcc889H9p+/fr1jBw5EoC33nqLadOmUVNTw9lnn81bb73VXHfxxRc337L7iiuuAGDBggVs2LCBiRMnMnHiRACGDRvG5s2bAbjhhhsYOXIkI0eObL5l9/r16znyyCP5xje+wYgRI5g0aVL2OqU89dRTjBs3jpqaGs444wxef/315tevrq6mpqam+eZ9jz76aPM/KhozZgxvvPFGh3+2pVTiewxjgXUppRcAImIJMAVoeQORKcCVxek7gZ9HRKSUUkScDrwAvFmBXiR1tgfmwP97urL7POgomDyv1dWDBw9m7NixPPjgg0yZMoUlS5Zw9tlnExH06dOHu+++m/3335/Nmzczbtw4vvSlL7X6f49/8YtfsO+++7J69WpWr16d3Tb7Jz/5CYMGDeK9997jhBNOYPXq1Xz3u9/lhhtuYPny5RxwwAHZvlauXMmiRYt4/PHHSSlx9NFHM378eAYOHEh9fT233347v/71r/nKV77CXXfdtcv/r3Deeedx0003MX78eH784x9z1VVXMX/+fObNm8eLL75I7969m09fXX/99dx8880cc8wxbN++nT59+uzOT7tNlTiVdCjwcov5huKykjUppUZgGzA4IvYDLgWuqkAfkj7CWp5OankaKaXEZZddRk1NDSeeeCJ///vfeeWVV1rdz4oVK5r/QNfU1FBTU9O87o477qC2tpYxY8awZs2aNm+Q99hjj3HGGWew33770bdvX84880z+9Kc/ATB8+HBGjx4N7PrW3tD0/yG2bt3K+PHjAZg5cyYrVqxo7vHcc8/ltttua/6G9THHHMPs2bNZsGABW7durfg3ryuxt1KxvPMNmFqruQq4MaW0vbV0b95BxCxgFsDQoUM70KakitjFO/vOdPrppzN79mxWrVrFW2+91fxOf/HixWzatImVK1fSq1cvhg0bVvJW2y2V+nvz4osvcv311/Pkk08ycOBAzj///Db3s6t7zX1wy25oum13W6eSWnPfffexYsUKli5dytVXX82aNWuYM2cOp556Kvfffz/jxo3j4Ycf5jOf+UyH9l9KJY4YGoBPtpivAja0VhMRPYH+wGvA0cB1EbEe+Hfgsoj4dqkXSSktTCkVUkqFIUOGVKBtSd1J3759mTBhAl/72teyi87btm3jwAMPpFevXixfvpyXXnppl/s57rjjWLx4MQDPPPMMq1evBppu2b3ffvvRv39/XnnlFR544L8ve/br16/kefzjjjuO3//+9+zYsYM333yTu+++my984Qu7Pbb+/fszcODA5qONW2+9lfHjx/P+++/z8ssvM3HiRK677jq2bt3K9u3bef755znqqKO49NJLKRQK/O1vf9vt19yVShwxPAkcERHDgb8D04BzdqpZCswE/i8wFfhDaora5p9gRFwJbE8p/bwCPUn6CJo+fTpnnnlm9gmlc889l9NOO41CocDo0aPbfOd88cUXc8EFF1BTU8Po0aMZO3Ys0PTf2MaMGcOIESM+dMvuWbNmMXnyZA4++GCWL1/evLy2tpbzzz+/eR9f//rXGTNmzC5PG7Xmlltu4aKLLmLHjh0cdthhLFq0iPfee48ZM2awbds2Ukp8//vfZ8CAAfzoRz9i+fLl9OjRg+rq6ub/RlcpFbntdkR8EZgP9AB+m1L6SUTMBepSSksjog9wKzCGpiOFaR9crG6xjytpCoY2P9TrbbelPcvbbnc/XX7b7ZTS/cD9Oy37cYvpt4Evt7GPKyvRiySpPH7zWZKUMRgktUt3/G+P/6rK/V0ZDJLa1KdPH7Zs2WI4dAMpJbZs2VLWl978D26S2lRVVUVDQwObNm3q6lbUDn369KGqqqrD2xsMktrUq1cvhg8f3tVtaA/xVJIkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyFQmGiDglItZGxLqImFNife+I+F1x/eMRMay4/KSIWBkRTxefj69EP5Kkjis7GCKiB3AzMBmoBqZHRPVOZRcCr6eUDgduBK4tLt8MnJZSOgqYCdxabj+SpPJU4ohhLLAupfRCSuldYAkwZaeaKcAtxek7gRMiIlJKf0kpbSguXwP0iYjeFehJktRBlQiGQ4GXW8w3FJeVrEkpNQLbgME71ZwF/CWl9E4FepIkdVDPCuwjSixLu1MTESNoOr00qdUXiZgFzAIYOnTo7ncpSWqXShwxNACfbDFfBWxorSYiegL9gdeK81XA3cB5KaXnW3uRlNLClFIhpVQYMmRIBdqWJJVSiWB4EjgiIoZHxD7ANGDpTjVLabq4DDAV+ENKKUXEAOA+4Acppf9TgV4kSWUqOxiK1wy+DSwDngPuSCmtiYi5EfGlYtl/AoMjYh0wG/jgI63fBg4HfhQRTxUfB5bbkySp4yKlnS8H7P0KhUKqq6vr6jYkqVuJiJUppUJbdX7zWZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSRmDQZKUMRgkSZmKBENEnBIRayNiXUTMKbG+d0T8rrj+8YgY1mLdD4rL10bEyZXoR5LUcWUHQ0T0AG4GJgPVwPSIqN6p7ELg9ZTS4cCNwLXFbauBacAI4BTgfxT3J0nqIpU4YhgLrEspvZBSehdYAkzZqWYKcEtx+k7ghIiI4vIlKaV3UkovAuuK+5MkdZFKBMOhwMst5huKy0rWpJQagW3A4HZuK0nagyoRDFFiWWpnTXu2bdpBxKyIqIuIuk2bNu1mi5Kk9qpEMDQAn2wxXwVsaK0mInoC/YHX2rktACmlhSmlQkqpMGTIkAq0LUkqpRLB8CRwREQMj4h9aLqYvHSnmqXAzOL0VOAPKaVUXD6t+Kml4cARwBMV6EmS1EE9y91BSqkxIr4NLAN6AL9NKa2JiLlAXUppKfCfwK0RsY6mI4VpxW3XRMQdwLNAI/CtlNJ75fYkSeq4aHrj3r0UCoVUV1fX1W1IUrcSEStTSoW26vzmsyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpYzBIkjIGgyQpU1YwRMSgiHgoIuqLzwNbqZtZrKmPiJnFZftGxH0R8beIWBMR88rpRZJUGeUeMcwBHkkpHQE8UpzPRMQg4ArgaGAscEWLALk+pfQZYAxwTERMLrMfSVKZyg2GKcAtxelbgNNL1JwMPJRSei2l9DrwEHBKSmlHSmk5QErpXWAVUFVmP5KkMpUbDJ9IKW0EKD4fWKLmUODlFvMNxWXNImIAcBpNRx2SpC7Us62CiHgYOKjEqh+28zWixLLUYv89gduBBSmlF3bRxyxgFsDQoUPb+dKSpN3VZjCklE5sbV1EvBIRB6eUNkbEwcCrJcoagAkt5quAP7aYXwjUp5Tmt9HHwmIthUIh7apWktRx5Z5KWgrMLE7PBO4pUbMMmBQRA4sXnScVlxER1wD9gX8vsw9JUoWUGwzzgJMioh44qThPRBQi4jcAKaXXgKuBJ4uPuSml1yKiiqbTUdXAqoh4KiK+XmY/kqQyRUrd76xMoVBIdXV1Xd2GJHUrEbEypVRoq85vPkuSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJCljMEiSMgaDJClTVjBExKCIeCgi6ovPA1upm1msqY+ImSXWL42IZ8rpRZJUGeUeMcwBHkkpHQE8UpzPRMQg4ArgaGAscEXLAImIM4HtZfYhSaqQcoNhCnBLcfoW4PQSNScDD6WUXkspvQ48BJwCEBF9gdnANWX2IUmqkHKD4RMppY0AxecDS9QcCrzcYr6huAzgauA/gB1l9iFJqpCebRVExMPAQSVW/bCdrxEllqWIGA0cnlL6fkQMa0cfs4BZAEOHDm3nS0uSdlebwZBSOrG1dRHxSkQcnFLaGBEHA6+WKGsAJrSYrwL+CHwe+GxErC/2cWBE/DGlNIESUkoLgYUAhUIhtdW3JKljyj2VtBT44FNGM4F7StQsAyZFxMDiRedJwLKU0i9SSoeklIYBxwL/1VooSJL2nHKDYR5wUkTUAycV54mIQkT8BiCl9BpN1xKeLD7mFpdJkvZCkVL3OytTKBRSXV1dV7chSd1KRKxMKRXaqvObz5KkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkjMEgScoYDJKkTKSUurqH3RYRm4CXurqP3XQAsLmrm9jDHPO/BsfcffxbSmlIW0XdMhi6o4ioSykVurqPPckx/2twzB89nkqSJGUMBklSxmDYcxZ2dQNdwDH/a3DMHzFeY5AkZTxikCRlDIYKiohBEfFQRNQXnwe2UjezWFMfETNLrF8aEc90fsflK2fMEbFvRNwXEX+LiDURMW/Pdr97IuKUiFgbEesiYk6J9b0j4nfF9Y9HxLAW635QXL42Ik7ek32Xo6NjjoiTImJlRDxdfD5+T/feEeX8jovrh0bE9oi4ZE/13ClSSj4q9ACuA+YUp+cA15aoGQS8UHweWJwe2GL9mcD/BJ7p6vF09piBfYGJxZp9gD8Bk7t6TK2MswfwPHBYsde/AtU71XwT+GVxehrwu+J0dbG+NzC8uJ8eXT2mTh7zGOCQ4vRI4O9dPZ7OHG+L9XcB/wu4pKvHU87DI4bKmgLcUpy+BTi9RM3JwEMppddSSq8DDwGnAEREX2A2cM0e6LVSOjzmlNKOlNJygJTSu8AqoGoP9NwRY4F1KaUXir0uoWnsLbX8WdwJnBARUVy+JKX0TkrpRWBdcX97uw6POaX0l5TShuLyNUCfiOi9R7ruuHJ+x0TE6TS96Vmzh/rtNAZDZX0ipbQRoPh8YImaQ4GXW8w3FJcBXA38B7CjM5ussHLHDEBEDABOAx7ppD7L1eYYWtaklBqBbcDgdm67NypnzC2dBfwlpfROJ/VZKR0eb0TsB1wKXLUH+ux0Pbu6ge4mIh4GDiqx6oft3UWJZSkiRgOHp5S+v/N5y67WWWNusf+ewO3AgpTSC7vf4R6xyzG0UdOebfdG5Yy5aWXECOBaYFIF++os5Yz3KuDGlNL24gFEt2Yw7KaU0omtrYuIVyLi4JTSxog4GHi1RFkDMKHFfBXwR+DzwGcjYj1Nv5cDI+KPKaUJdLFOHPMHFgL1KaX5FWi3szQAn2wxXwVsaKWmoRh2/YHX2rnt3qicMRMRVcDdwHkppec7v92ylTPeo4GpEXEdMAB4PyLeTin9vPPb7gRdfZHjo/QAfkp+Ifa6EjWDgBdpuvg6sDg9aKeaYXSfi89ljZmm6yl3AR/r6rG0Mc6eNJ0/Hs5/X5gcsVPNt8gvTN5RnB5BfvH5BbrHxedyxjygWH9WV49jT4x3p5or6eYXn7u8gY/Sg6Zzq48A9cXnD/74FYDftKj7Gk0XINcBF5TYT3cKhg6PmaZ3ZAl4Dniq+Ph6V49pF2P9IvBfNH1y5YfFZXOBLxWn+9D0iZR1wBPAYS22/WFxu7XspZ+8quSYgcuBN1v8Xp8CDuzq8XTm77jFPrp9MPjNZ0lSxk8lSZIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKWMwSJIyBoMkKfP/Afb4kBQPpEG3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['train'], label='Training loss')\n",
    "plt.plot(losses['validation'], label='Validation loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
